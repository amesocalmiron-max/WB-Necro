# WB Revival v2 «Некромант» — конспект для переноса в новый чат
Дата: 2026-02-19

## 1) Контекст проекта
Мы строили staged pipeline A–K для 64 SKU из файла WB_INPUT_64_FROM_POCKETS_POD.xlsx (лист INPUT_64).
Промежуточные артефакты храним канонично в *.jsonl, кэш запросов WB — в .wb_cache. Отчёты: XLSX + HTML.

В процессе:
- Починили Stage D (serp_relevance_pass был слишком жёсткий → rel50≈0). Теперь на каждый SKU выбирается 2–5 валидных запросов, доля ненулевых rel50 ~51.5%.
- Нашли стопор Stage G: при max_tokens=800 JSON резался → parse fail → fallback KEEP-ALL → llm_used=False (хотя вызов к OpenAI был).
- Добавили stage-specific max_tokens: C=800, G=3000, J=6000, K=15000, улучшили UX паузы (показываем стадию + WB/LLM + VPN hint), добавили меню выбора стадий.
- Улучшили финальный HTML (дашборд), добавили “evidence/FACTS” для Exec Summary, фиксы вёрстки карточек и list_to_ul.

## 2) Поворот в логике: «мертвые карточки» требуют другой модели решений
Главный инсайт: сравнивать “нашу мёртвую карточку” с “живым рынком” как будто товар активно продаётся — фундаментально неверно.

Проблемы старой логики (обобщение):
- Наша “цена” на мёртвом SKU часто мусор (распродажа/заглушка/устаревшая) → решения по цене скачут.
- Позиции в выдаче плавают по ключам из‑за рекламы и ставок → нельзя делать вывод по одной выдаче/одному ключу.
- Можно получить “рынок жив” по историческим отзывам, хотя последний отзыв был год назад (кладбище исторических данных).

Итог: нужен подход «Некромант» — оценка потенциала рынка и “кармы” карточки, а не сравнение “мы vs конкуренты” по мёртвым метрикам.

## 3) Что берём из своих карточек (own-card)
Own-card нужна НЕ для сравнения цены, а чтобы:
- извлечь модель телефона (phone model) и тип чехла/фичи
- собрать “карму” карточки (rating, total feedbacks)
- получить текст/атрибуты для генерации запросов и фильтров релевантности

Правило: own_price в решениях игнорируем.

## 4) Ключевые идеи для v2 (сводно)
### 4.1 Market Pulse по отзывам (главное)
Самый полезный бесплатный прокси спроса без Seller API: Review Velocity.
Считаем по конкурентам (по imt_id/root id) для лидеров выдачи:
- recent_30d (и/или recent_90d)
- days_since_last_review
- sample_n (сколько конкурентов реально проверили)
Плохие отзывы тоже считаются: важна активность.

Почему важно: исторические “50k отзывов” не означают живой спрос сегодня.

### 4.2 Supply Pressure и Market Structure (вторые по важности)
- Stock proxy: суммарный qty по sizes/stocks (как сигнал, не как “точная бухгалтерия”)
- Seller concentration: уникальные продавцы в топе, доля top‑1, HHI (если делаем)
Риски:
- DUMPING_PRESSURE — навал предложения и цена внизу рынка
- MONOPOLY_DANGER — выдача монополизирована несколькими продавцами

### 4.3 Цена рынка: робастно и “как видит покупатель”
Цена лидера/топ‑3 часто демпинг/слив/заглушка.
Берём топ‑10 по ключу:
- базовая статистика: медиана
- отсечение аномалий (trimmed/winsorized) + флаг outliers
Желательно использовать “client price” (с учётом скидок/СПП), если доступно из SERP эндпоинта.

### 4.4 Мульти-ключевой мир
Один SKU может быть на разных позициях по разным ключам из‑за РК/ставок.
Решения строим по нескольким валидным ключам (2–5), а итог агрегируем (по лучшему ключу или по медиане/majority).

### 4.5 Prompting для LLM
LLM должна формулировать выводы только по фактам (FACTS/EVIDENCE), без выдуманных цифр.
Сырой дамп вложенного JSON в промпт ухудшает внимание модели → лучше:
- компактные секции (или XML‑теги на английском) + русские пояснения
- JSON-only output
rationale — RU, risk_flags — EN UPPER_SNAKE_CASE.

### 4.6 Basket routing / deep-card (устойчивость данных)
Жёстко зашитая логика basket-XX может устаревать (WB добавляет новые ноды).
Deep enrichment (wbbasket) должен быть опциональным и иметь fallback (не ломать пайплайн), иначе решения принимаются по “огрызкам данных”.

### 4.7 Tokenization/keyword gap
Простой split по пробелам даёт мусор на русском (чехол/чехлу/чехлом).
Нужен минимальный стемминг/нормализация, чтобы keyword_gap не превращался в спам‑советы.

## 5) Главная бизнес-уточнённая цель v2: два рынка на один SKU
Мы не “анализируем карточку”, мы решаем: есть ли смысл возвращать SKU в работу.
Для каждого SKU строим два независимых “рынка”:

### Рынок 1: Чехлы для модели телефона (общий рынок модели)
Вопрос: продаётся ли вообще что-то по чехлам на эту модель телефона (телефон жив или умер).

### Рынок 2: Конкретный тип (приоритет): TPU силиконовый чехол с карманом под карту
Вопрос: даже если модель жива, продаётся ли именно тип “TPU + карман под карту” для этой модели.

Торговля только чехлами, но типов много (книга/противоударный/водонепроницаемый и т.п.). Сейчас фокус: TPU + карман.

## 6) Матрица решений v2 (final decision)
- Если общий рынок модели (Рынок 1) мёртв → DROP.
- Если общий рынок жив, но рынок типа (Рынок 2) мёртв → обычно DROP (или пометка alt_strategy: “модель жива, но карман не востребован”).
- Если рынок типа жив:
  - если “карма” токсична (низкий рейтинг при достаточном числе отзывов) → CLONE_NEW_CARD.
  - иначе → REVIVE_FAST или REVIVE_REWORK (по контент‑долгу).

Контент‑анализ вторичен: он нужен для выбора FAST vs REWORK и списка задач, но не для ответа “есть ли смысл по рынку”.

## 7) Предлагаемая новая структура стадий (скелет v2)
Ниже вариант, который можно строить на базе текущего staged A–K, добавив подэтапы.

A) INPUT  
- чтение 64 SKU, run_manifest.

B) OWN FETCH (WB-only)  
- own карточка: title/attrs/описание/карма, price игнор в решениях.

C) INTENT EXTRACT (rules-first)  
- phone_model, case_type, feature_flags (карман, TPU).

D) QUERY BUILD (2 кластера) (rules + LLM)  
- D1: phone-market queries (чехлы на модель)  
- D2: type-market queries (TPU+карман на модель)

E) SERP SNAPSHOT + VALIDATION (WB-only)  
- снимаем выдачу по каждому запросу, выбираем 2–5 валидных на кластер.

F) COMPETITOR POOL (WB-only)  
- строим пул отдельно для каждого кластера: LEADERS + CLOSEST_MATCH + seller diversity, дедуп по imt_id.

G) LITE FETCH (WB-only)  
- минимальные поля конкурентов: imt_id, seller_id, rating/feedbacks, price fields, stocks proxy (если есть).

H) RELEVANCE FILTER (rules-first + optional LLM)  
- для phone-market: must phone_model + case intent  
- для type-market: must phone_model + TPU + карман/карта  
- опц. LLM KEEP/DROP только на пограничных.

I) MARKET PULSE (WB-only)  
- отзывы по imt_id: recent_30/90, days_since_last, sample_n, кэш + early-stop.

J) SUPPLY/STRUCTURE (WB-only)  
- price robust (median + outlier flags, лучше client price)  
- stock proxy (median + концентрация)  
- seller concentration (unique sellers, top1 share/HHI)  
- риск-флаги.

K) CLUSTER VERDICTS (rules)  
- отдельно phone-market status и type-market status: ALIVE/SLOW/DEAD + confidence.

L) FINAL DECISION (LLM формулировка по FACTS)  
- применяем матрицу решений, формируем verdict + rationale RU + risk_flags EN + backlog RU.  
- LLM не выдумывает цифры, берёт только FACTS.

M) REPORTS (renderer + LLM exec summary)  
- XLSX + HTML с двумя рынками (общий vs тип) и видимыми фактами: pulse/supply/structure + решение.

## 8) Принципы сохранения данных
- Канон: JSONL по стадиям + meta {schema_version, run_id, nm_id str, vendor_code, ts, stage}.
- .wb_cache сохраняем и используем для экономии запросов WB.
- Все вычисленные агрегаты (FACTS) сохраняем, чтобы LLM и HTML ссылались на реальные числа.

## 9) Почему решили идти по v2
1) Мёртвые SKU нельзя сравнивать по “нашей цене” и “нашей позиции” (они нерелевантны/шумные).
2) Нужны измерители “пульса” и “структуры рынка” без платного API.
3) Разделение рынка на “модель” и “тип” отвечает бизнес‑вопросу: стоит ли возрождать именно TPU+карман, а не чехлы вообще.
4) LLM должна писать объяснения, но не быть источником данных: факты считает код.

--- 
Конец конспекта.
